<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>LLM Agent POC â€” OpenAI-style tools</title>
  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-sRIl4kxILFvY47J16cr9ZwB07vP4J8+LH7qKQnuqkuIAvNWLzeN8tE5YBujZqJLB" crossorigin="anonymous">
  <style>
    body { background: #0b1020; color: #e6e9ef; }
    .card { background: #141a33; border: 1px solid #2a3158; }
    .form-control, .form-select { background:#0f1430; color:#e6e9ef; border-color:#2a3158; }
    .btn-primary { background:#5865f2; border-color:#5865f2; }
    .message { white-space: pre-wrap; }
    .msg-user { background:#0f1430; }
    .msg-agent { background:#121a3a; }
    .tool-badge { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
    #codeOutput { min-height: 120px; font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; background:#0f1430; color:#cde; padding: .5rem; border-radius:.5rem; border:1px solid #2a3158; overflow:auto; }
    label, .form-label, .form-check-label, small, .form-text 
    {
    color: #e6e9ef !important;
    }
  </style>
</head>
<body>
<div class="container py-4">
  <div id="alerts"></div>
  <div class="d-flex align-items-center gap-2 mb-3">
    <h1 class="h4 m-0">ðŸ”§ LLM Agent POC</h1>
    <button id="pickModel" class="btn btn-sm btn-primary">Pick Model</button>
    <button id="aiPipeLogin" class="btn btn-sm btn-outline-light">AI Pipe Info</button>
    <span class="ms-auto small" id="providerBadge"></span>
  </div>

  <div class="row g-3">
    <div class="col-lg-8">
      <div class="card">
        <div class="card-header d-flex justify-content-between align-items-center">
          <p class="text-bg-light">Conversation</p>
          <div class="small">Model: <span id="modelName">-</span></div>
        </div>
        <div class="card-body" id="chat" style="height: 52vh; overflow:auto"></div>
        <div class="card-footer">
          <form id="chatForm" class="d-flex gap-2">
            <input id="userInput" class="form-control" placeholder="Type your messageâ€¦" autocomplete="off" />
            <button class="btn btn-primary" type="submit">Send</button>
          </form>
        </div>
      </div>

      <div class="card mt-3">
        <div class="card-header"><strong>JavaScript Sandbox Output</strong></div>
        <div class="card-body">
          <div id="codeOutput" aria-live="polite"></div>
        </div>
      </div>
    </div>

    <div class="col-lg-4">
      <div class="card">
        <div class="card-header"><strong class="text-bg-light">Tool Settings</strong></div>
        <div class="card-body">
          <div class="mb-3">
            <label class="form-label">AI Pipe Token</label>
            <input id="aiPipeToken" class="form-control" placeholder="Get token from aipipe.org" />
            <div class="small text-muted mt-1">Paste your AI Pipe API token here</div>
          </div>
          <div class="mb-3">
            <label class="form-label">Google Search â€” API Key</label>
            <input id="googleKey" class="form-control" placeholder="AIzaâ€¦ (Programmable Search JSON API)" />
          </div>
          <div class="mb-3">
            <label class="form-label">Google Search â€” CX (Search Engine ID)</label>
            <input id="googleCx" class="form-control" placeholder="cx id" />
          </div>
          <div class="mb-3">
            <label class="form-label">AI Pipe</label>
            <div class="small">Use <code>aipipe.org</code> proxy to call OpenAI/OpenRouter from the browser.</div>
            <div id="aiPipeStatus" class="mt-1 small text-secondary">No token set</div>
          </div>
          <div class="mb-3">
            <label class="form-label">Provider Base URL</label>
            <input id="baseUrl" class="form-control" placeholder="https://api.openai.com/v1 or https://openrouter.ai/api/v1" />
          </div>
          <div class="mb-3">
            <label class="form-label">API Key (if needed)</label>
            <input id="apiKey" class="form-control" placeholder="sk-â€¦ or openrouter key" />
          </div>
          <div class="mb-3">
            <label class="form-label">Model</label>
            <input id="model" class="form-control" placeholder="gpt-4o-mini, openai/gpt-4.1-mini, mistralai/mistral-small, â€¦" />
          </div>
          <div class="mb-1 small text-secondary">Tip: Use the <em>Pick Model</em> button to auto-fill Base URL, Key, and list of models.</div>
        </div>
      </div>

      <div class="card mt-3">
        <div class="card-header"><strong class="text-bg-light">About</strong></div>
        <div class="card-body small">
          <p class="text-bg-light">Agent loop with OpenAI-style <em>tool calling</em>. Tools: Google Search, AI Pipe proxy calls, and sandboxed JS execution.</p>
          <p class="text-bg-light">Design goals: tiny, hackable, single file. Replace any part as you like.</p>
        </div>
      </div>
    </div>
  </div>
</div>

<!-- Libraries -->
<script type="module">

  import { openaiConfig } from "https://cdn.jsdelivr.net/npm/bootstrap-llm-provider@1.3.1"; // docs: libraries.io/npm/bootstrap-llm-provider

  // --- Initialize state object ---
  const state = {
    baseUrl: localStorage.getItem('baseUrl') || '',
    apiKey: localStorage.getItem('apiKey') || '',
    model: localStorage.getItem('model') || '',
    aiPipeToken: '',
    messages: []
  };

  // --- Elements ---
  const els = {
    alerts: document.getElementById('alerts'),
    chat: document.getElementById('chat'),
    form: document.getElementById('chatForm'),
    input: document.getElementById('userInput'),
    baseUrl: document.getElementById('baseUrl'),
    apiKey: document.getElementById('apiKey'),
    model: document.getElementById('model'),
    modelName: document.getElementById('modelName'),
    providerBadge: document.getElementById('providerBadge'),
    googleKey: document.getElementById('googleKey'),
    googleCx: document.getElementById('googleCx'),
    codeOutput: document.getElementById('codeOutput'),
    aiPipeStatus: document.getElementById('aiPipeStatus'),
    aiPipeToken: document.getElementById('aiPipeToken')
  };

  // --- Simple token management ---
  function updateAiPipeStatus() {
    const token = els.aiPipeToken.value.trim();
    if (token) {
      state.aiPipeToken = token;
      // Save token to localStorage for persistence
      localStorage.setItem('aiPipeToken', token);
      els.aiPipeStatus.textContent = "Token set - ready to use";
      els.aiPipeStatus.className = 'mt-1 small text-success';
      
      // Auto-set Base URL if not already AI Pipe
      if (!els.baseUrl.value.includes('aipipe.org')) {
        els.baseUrl.value = 'https://aipipe.org/openrouter/v1';
        saveSettings();
      }
      return true;
    }
    els.aiPipeStatus.textContent = "No token set";
    els.aiPipeStatus.className = 'mt-1 small text-secondary';
    state.aiPipeToken = '';
    localStorage.removeItem('aiPipeToken');
    return false;
  }

  // Load saved token on page load
  const savedToken = localStorage.getItem('aiPipeToken');
  if (savedToken) {
    els.aiPipeToken.value = savedToken;
    state.aiPipeToken = savedToken;
  }
  
  // Update status immediately on load
  updateAiPipeStatus();

  // Update status when token field changes
  els.aiPipeToken.addEventListener('input', updateAiPipeStatus);
  els.aiPipeToken.addEventListener('paste', () => setTimeout(updateAiPipeStatus, 100));

  // Load saved settings
  els.baseUrl.value = state.baseUrl; 
  els.apiKey.value = state.apiKey; 
  els.model.value = state.model;

  function saveSettings() {
    state.baseUrl = els.baseUrl.value.trim();
    state.apiKey  = els.apiKey.value.trim();
    state.model   = els.model.value.trim();
    localStorage.setItem('baseUrl', state.baseUrl);
    localStorage.setItem('apiKey', state.apiKey);
    localStorage.setItem('model', state.model);
    els.modelName.textContent = state.model || '-';
    els.providerBadge.innerHTML = `<span class="badge text-bg-secondary">${new URL(state.baseUrl||'https://example.com').host}</span>`;
  }
  
  ['change','blur','keyup'].forEach(ev => {
    els.baseUrl.addEventListener(ev, saveSettings);
    els.apiKey.addEventListener(ev, saveSettings);
    els.model.addEventListener(ev, saveSettings);
  });

  // Bootstrap Alerts
  function alert(html, variant='danger', timeout=6000){
    const id = 'al_'+Math.random().toString(36).slice(2);
    const div = document.createElement('div');
    div.className = `alert alert-${variant} alert-dismissible fade show`;
    div.role = 'alert';
    div.innerHTML = html + `<button type="button" class="btn-close" data-bs-dismiss="alert"></button>`;
    els.alerts.appendChild(div);
    if (timeout) setTimeout(()=>div.remove(), timeout);
  }

  // Chat UI helpers
  function addMsg(role, text){
    const wrap = document.createElement('div');
    wrap.className = `p-2 rounded mb-2 message ${role==='user'?'msg-user':'msg-agent'}`;
    wrap.innerHTML = `<div class="small text-secondary">${role.toUpperCase()}</div><div>${escapeHtml(text)}</div>`;
    els.chat.appendChild(wrap);
    els.chat.scrollTop = els.chat.scrollHeight;
  }
  const escapeHtml = (s)=> s.replace(/[&<>]/g,c=>({"&":"&amp;","<":"&lt;",">":"&gt;"}[c]));

  // Model Picker via Bootstrap LLM Provider (auto fetch /models)
  document.getElementById('pickModel').onclick = async ()=>{
    try{
      const cfg = await openaiConfig({
        defaultBaseUrls: [
          'https://api.openai.com/v1',
          'https://openrouter.ai/api/v1',
          'https://aipipe.org/openrouter/v1'
        ],
        help: '<div class="alert alert-info">Use OpenAI / OpenRouter / AI Pipe. API key may be optional for AI Pipe (handled after login).</div>',
        show: true
      });
      els.baseUrl.value = cfg.baseUrl || cfg.baseURL || '';
      els.apiKey.value = cfg.apiKey || '';
      els.model.value = (cfg.models && cfg.models[0]) || els.model.value;
      saveSettings();
    } catch (e) {
      alert(`<strong>Model picker failed:</strong> ${escapeHtml(e.message||String(e))}`);
    }
  };

  // Simple info button instead of login
  document.getElementById('aiPipeLogin').onclick = () => {
    alert(`
      <strong>How to get AI Pipe token:</strong><br>
      1. Go to <a href="https://aipipe.org" target="_blank">aipipe.org</a><br>
      2. Sign up/login<br>
      3. Copy your API token<br>
      4. Paste it in the "AI Pipe Token" field above
    `, 'info', 10000);
  };

  // --- Tools (OpenAI-style function calling) ---
  const tools = [
    {
      type: 'function',
      function: {
        name: 'search_google',
        description: 'Search the web and return top snippets from Google Programmable Search.',
        parameters: {
          type: 'object',
          properties: {
            query: { type: 'string', description: 'Search query' },
            num: { type: 'number', description: 'Number of results', default: 5 }
          },
          required: ['query']
        }
      }
    },
    {
      type: 'function',
      function: {
        name: 'aipipe_call',
        description: 'Call an LLM via AI Pipe proxy (OpenRouter-compatible). Returns the raw JSON response.',
        parameters: {
          type: 'object',
          properties: {
            model: { type: 'string', description: 'Model id, e.g., openai/gpt-4.1-nano' },
            input: { type: 'string', description: 'Prompt text' }
          },
          required: ['model','input']
        }
      }
    },
    {
      type: 'function',
      function: {
        name: 'execute_js',
        description: 'Run JavaScript in a sandboxed iframe/worker and return console output + result string.',
        parameters: {
          type: 'object',
          properties: {
            code: { type: 'string', description: 'JavaScript source to run' }
          },
          required: ['code']
        }
      }
    }
  ];

  // Google Search (Programmable Search JSON API)
  async function searchGoogle({ query, num=5 }){
    const key = els.googleKey.value.trim();
    const cx  = els.googleCx.value.trim();
    if (!key || !cx) throw new Error('Set Google API key and CX in Tool Settings.');
    const url = new URL('https://www.googleapis.com/customsearch/v1');
    url.searchParams.set('key', key);
    url.searchParams.set('cx', cx);
    url.searchParams.set('q', query);
    url.searchParams.set('num', Math.min(10, Math.max(1, num)));
    const res = await fetch(url);
    if (!res.ok) throw new Error('Google Search failed: '+res.status+' '+res.statusText);
    const data = await res.json();
    const items = (data.items||[]).map(it=>({ title: it.title, link: it.link, snippet: it.snippet }));
    return { query, items };
  }

  // AI Pipe proxy call
  async function aiPipeProxy({ model, input }) {
    const token = els.aiPipeToken.value.trim() || state.aiPipeToken;
    
    if (!token) throw new Error('AI Pipe token not set. Please paste your token in the AI Pipe Token field.');

    const res = await fetch('https://aipipe.org/openrouter/v1/chat/completions', {
      method: 'POST',
      headers: { 
        "Authorization": `Bearer ${token}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({ model, messages: [{ role: "user", content: input }] })
    });
    if (!res.ok) throw new Error('AI Pipe call failed: ' + res.status + ' ' + res.statusText);
    return await res.json();
  }

  // JS sandbox: run code inside a sandboxed iframe via postMessage
  async function runJsSandbox(code){
    const iframe = document.createElement('iframe');
    iframe.sandbox = 'allow-scripts';
    iframe.style.display = 'none';
    iframe.srcdoc = `<!doctype html><html><body><script>
      const logs=[];
      const log=(...a)=>{ logs.push(a.map(String).join(' ')); };
      console.log = log; console.error = log; console.warn = log; console.info = log;
      addEventListener('message', (e)=>{
        if (e.data && e.data.type==='RUN') {
          let result='';
          try {
            // eslint-disable-next-line no-eval
            const r = eval(e.data.code);
            result = (typeof r==='undefined') ? 'undefined' : String(r);
            parent.postMessage({ type:'DONE', ok:true, logs, result }, '*');
          } catch (err) {
            parent.postMessage({ type:'DONE', ok:false, logs, error: String(err) }, '*');
          }
        }
      });
    <\/script></body></html>`;
    document.body.appendChild(iframe);
    const done = new Promise((resolve)=>{
      const onMsg = (e)=>{
        if (e.data && e.data.type==='DONE') {
          window.removeEventListener('message', onMsg);
          resolve(e.data);
          setTimeout(()=>iframe.remove(),0);
        }
      };
      window.addEventListener('message', onMsg);
    });
    iframe.contentWindow.postMessage({ type:'RUN', code }, '*');
    const data = await done;
    const out = [];
    if (data.logs && data.logs.length) out.push('console:\n'+data.logs.join('\n'));
    if (data.ok) out.push('result:\n'+data.result);
    else out.push('error:\n'+data.error);
    els.codeOutput.textContent = out.join('\n\n');
    return { ok: data.ok, logs: data.logs, result: data.result||'', error: data.error||'' };
  }

  // Core LLM call (OpenAI-style /chat/completions)
  async function callLLM(messages){
    saveSettings();
    const url = `${state.baseUrl.replace(/\/$/,'')}/chat/completions`;
    const headers = { 'Content-Type': 'application/json' };

    if (state.baseUrl.includes('aipipe.org')) {
      // Use the manually entered token from the input field
      const token = els.aiPipeToken.value.trim();
      if (!token) throw new Error('AI Pipe requires a token. Please paste your token in the AI Pipe Token field.');
      headers['Authorization'] = `Bearer ${token}`;
    } else if (state.apiKey) {
      headers['Authorization'] = `Bearer ${state.apiKey}`;
    }

    const body = { model: state.model, messages, tools, tool_choice: 'auto' };
    
    console.log('Making LLM call to:', url);
    console.log('Headers:', headers);
    console.log('Body:', JSON.stringify(body, null, 2));
    
    const res = await fetch(url, { method:'POST', headers, body: JSON.stringify(body) });
    if (!res.ok) {
      const errorText = await res.text();
      console.error('LLM call failed:', res.status, res.statusText, errorText);
      throw new Error(`LLM error: ${res.status} ${res.statusText} - ${errorText}`);
    }

    const data = await res.json();
    const choice = data.choices?.[0];
    return choice?.message || { role:'assistant', content:'', tool_calls:[] };
  }

  // Handle a tool call message from model
  async function handleToolCall(tc){
    const { function: fn } = tc;
    const name = fn?.name; let args = {};
    try { args = fn?.arguments ? JSON.parse(fn.arguments) : {}; }
    catch(e){ throw new Error('Bad tool args for '+name+': '+e.message); }

    if (name === 'search_google') {
      const out = await searchGoogle(args);
      return { role: 'tool', tool_call_id: tc.id, name, content: JSON.stringify(out) };
    }
    if (name === 'aipipe_call') {
      const out = await aiPipeProxy(args);
      return { role: 'tool', tool_call_id: tc.id, name, content: JSON.stringify(out) };
    }
    if (name === 'execute_js') {
      const out = await runJsSandbox(args.code||'');
      return { role: 'tool', tool_call_id: tc.id, name, content: JSON.stringify(out) };
    }
    throw new Error('Unknown tool: '+name);
  }

  // Agent loop
  async function agentTurn(userText){
    addMsg('user', userText);
    state.messages.push({ role:'user', content: userText });

    while (true) {
      const msg = await callLLM(state.messages);
      const assistantText = msg.content || '';
      if (assistantText) addMsg('assistant', assistantText);

      const toolCalls = msg.tool_calls || [];
      if (!toolCalls.length) {
        state.messages.push({ role: 'assistant', content: assistantText });
        break; // done, wait for next user input
      }

      // Execute tool calls (in parallel) and append results
      try {
        const results = await Promise.all(toolCalls.map(handleToolCall));
        state.messages.push({ role: 'assistant', content: assistantText, tool_calls: toolCalls });
        state.messages.push(...results);
      } catch (e) {
        alert(`<strong>Tool error:</strong> ${escapeHtml(e.message||String(e))}`);
        state.messages.push({ role: 'assistant', content: assistantText });
        break;
      }
    }
  }

  // Wire up chat form
  els.form.addEventListener('submit', async (e)=>{
    e.preventDefault();
    const text = els.input.value.trim(); if (!text) return;
    els.input.value = '';
    try{
      if (!els.baseUrl.value || !els.model.value) throw new Error('Pick a model/base URL first.');
      await agentTurn(text);
    } catch (err) {
      alert(`<strong>Agent error:</strong> ${escapeHtml(err.message||String(err))}`);
    }
  });

  // On load, show provider badge
  saveSettings();
</script>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>